Okay, here's a concrete 3-line answer:
 * LLM as a Judge automatically evaluates the Gen-AI's initial compliance answers for quality and accuracy against the provided policy context.
 * It acts as a supplementary check, offering scalable and consistent assessment alongside human advisor reviews and NLP similarity scores.
 * The key added value is its ability to judge deeper semantic correctness and policy alignment, going beyond surface-level metric comparisons.
